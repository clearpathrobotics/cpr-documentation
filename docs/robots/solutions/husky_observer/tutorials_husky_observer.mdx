---
title: Husky Observer Tutorials
sidebar_label: Tutorials
sidebar_position: 3
---

import ComponentIntroductionHuskyObserver from "/components/introduction_husky_observer.mdx";
import Support from "/components/support.mdx";

<ComponentIntroductionHuskyObserver />

## Husky Observer Overview

### Introduction

Husky Observer is a fully integrated system that enables robotics developers to accelerate inspection solutions.
It is built on top of the versatile [Husky](/docs/robots/outdoor_robots/husky/user_manual_husky) base platform
The tutorial topics are listed in the right column and presented in the suggested reading order.

For more information or to receive a quote, please [visit us online](http://clearpathrobotics.com/husky).

:::note

These tutorials assume that you are comfortable working with ROS. We recommend starting with our
[ROS tutorial](https://www.clearpathrobotics.com/assets/guides/noetic/ros/index.html) if you are not familiar with ROS already.

:::

---

## Husky ROS Packages {#husky-ros-packages}

The Husky Observer is built on the the Husky platform, which fully supports ROS. All of the packages are available in [Husky GitHub](https://github.com/husky).
Refer to the [Husky Tutorials](/docs/robots/outdoor_robots/husky/tutorials_husky/tutorials_husky_ros1#husky-ros-packages) for additional details.

---

## Using Husky Observer {#using-husky-observer}

### Simulating Husky Observer {#simulating-husky-observer}

Whether you actually have a Husky Observer robot or not, the simulator is a great way to get started with ROS
robot development. In this tutorial, we will go through the basics of starting Gazebo and RViz and how to drive
your Husky Observer around.

As Husky Observer is built on top of the Husky base robot, you can follow the [Husky Tutorials](/docs/robots/outdoor_robots/husky/tutorials_husky/tutorials_husky_ros1#simulating-husky)
with the following modifications:

1. TODO: set a specific environment variable or run a certain script to set environment varibles to get all the
   environment variables set up.

When you launch the Husky Observer in Gazebo, it should look similar to the following.

<center>
  <figure>
    <img
      src="/img/robot_images/husky_observer_images/husky_observer_gazebo_playpen.png"
      width="800"
    />
    <figcaption>Simulated Husky Observer in the Play Pen (TODO: new image)</figcaption>
  </figure>
</center>

:::note

See also [Additional Simulation Worlds](/docs/robots/outdoor_robots/husky/tutorials_husky/tutorials_husky_ros1#additional-sim).

:::

#### Customizing Husky Observer's Payload

TODO: update the example below with a different sensors (because RealSense is already on the Observer)
and choose the position for either the front or rear mount points.

You can also add additional sensors by creating a customized URDF and setting the `HUSKY_URDF_EXTRAS` environment
variable to point to it.

For example, let's suppose you want to equip Husky with an Intel RealSense D435 camera.
First, install the `realsense2_camera` and `realsense2_description` packages, along with the gazebo plugins:

```
sudo apt-get install ros-$ROS_DISTRO-realsense2-camera ros-$ROS_DISTRO-realsense2-description ros-$ROS_DISTRO-gazebo-plugins
```

Then create your customized URDF file, for example `$HOME/Desktop/realsense.urdf.xacro`. Put the following in it:

```markup
<?xml version="1.0"?>
<robot xmlns:xacro="http://ros.org/wiki/xacro">

  <link name="front_realsense" />

  <!--
    The gazebo plugin aligns the depth data with the Z axis, with X=left and Y=up
    ROS expects the depth data along the X axis, with Y=left and Z=up
    This link only exists to give the gazebo plugin the correctly-oriented frame
  -->
  <link name="front_realsense_gazebo" />
  <joint name="front_realsense_gazebo_joint" type="fixed">
    <parent link="front_realsense"/>
    <child link="front_realsense_gazebo"/>
    <origin xyz="0.0 0 0" rpy="-1.5707963267948966 0 -1.5707963267948966"/>
  </joint>

  <gazebo reference="front_realsense">
    <turnGravityOff>true</turnGravityOff>
    <sensor type="depth" name="front_realsense_depth">
      <update_rate>30</update_rate>
      <camera>
        <!-- 75x65 degree FOV for the depth sensor -->
        <horizontal_fov>1.5184351666666667</horizontal_fov>
        <vertical_fov>1.0122901111111111</vertical_fov>

        <image>
          <width>640</width>
          <height>480</height>
          <format>RGB8</format>
        </image>
        <clip>
          <!-- give the color sensor a maximum range of 50m so that the simulation renders nicely -->
          <near>0.01</near>
          <far>50.0</far>
        </clip>
      </camera>
      <plugin name="kinect_controller" filename="libgazebo_ros_openni_kinect.so">
        <baseline>0.2</baseline>
        <alwaysOn>true</alwaysOn>
        <updateRate>30</updateRate>
        <cameraName>realsense</cameraName>
        <imageTopicName>color/image_raw</imageTopicName>
        <cameraInfoTopicName>color/camera_info</cameraInfoTopicName>
        <depthImageTopicName>depth/image_rect_raw</depthImageTopicName>
        <depthImageInfoTopicName>depth/camera_info</depthImageInfoTopicName>
        <pointCloudTopicName>depth/color/points</pointCloudTopicName>
        <frameName>front_realsense_gazebo</frameName>
        <pointCloudCutoff>0.105</pointCloudCutoff>
        <pointCloudCutoffMax>8.0</pointCloudCutoffMax>
        <distortionK1>0.00000001</distortionK1>
        <distortionK2>0.00000001</distortionK2>
        <distortionK3>0.00000001</distortionK3>
        <distortionT1>0.00000001</distortionT1>
        <distortionT2>0.00000001</distortionT2>
        <CxPrime>0</CxPrime>
        <Cx>0</Cx>
        <Cy>0</Cy>
        <focalLength>0</focalLength>
        <hackBaseline>0</hackBaseline>
      </plugin>
    </sensor>
  </gazebo>

  <link name="front_realsense_lens">
    <visual>
      <origin xyz="0.02 0 0" rpy="${pi/2} 0 ${pi/2}" />
      <geometry>
        <mesh filename="package://realsense2_description/meshes/d435.dae" />
      </geometry>
      <material name="white" />
    </visual>
  </link>

  <joint type="fixed" name="front_realsense_lens_joint">
    <!-- Offset the camera 2cm backwards and 1cm up -->
    <origin xyz="-0.02 0 0.01" rpy="0 0 0" />
    <parent link="top_plate_front_link" />
    <child link="front_realsense_lens" />
  </joint>
  <joint type="fixed" name="front_realsense_joint">
    <origin xyz="0.025 0 0" rpy="0 0 0" />
    <parent link="front_realsense_lens" />
    <child link="front_realsense" />
  </joint>
</robot>
```

This file defines the additional links for adding a RealSense camera to the robot, as well as
configuring the `openni_kinect` plugin for Gazebo to simulate data from a depth camera. The
camera itself will be connected to the Husky's `top_plate_front_link` link. This places the
camera at the very front edge of the robot's top cover-plate.

Now, set the `HUSKY_URDF_EXTRAS` environment variable and try viewing the Husky model:

```
export HUSKY_URDF_EXTRAS=$HOME/Desktop/realsense.urdf.xacro
roslaunch husky_viz view_model.launch
```

You should see the Husky model in RViz, with the RealSense camera mounted to it:

<center>
  <figure>
    <img
      src="/img/robot_images/husky_images/husky_realsense.png"
      width="800"
    />
    <figcaption>Husky with a RealSense D435 connected to it</figcaption>
  </figure>
</center>

You can view the sensor data from the RealSense camera by running

```
roslaunch husky_viz view_robot.launch
```

and adding the camera and pointcloud from the `/realsense/color/image_raw` and
`/realsense/depth/color/points` topics:

<center>
  <figure>
    <img
      src="/img/robot_images/husky_images/husky_rviz_realsense.png"
      width="800"
    />
    <figcaption>Husky with a RealSense in RViz showing pointcloud and RGB topics</figcaption>
  </figure>
</center>

### Interfacing with Husky Observer

Both simulated and real Husky Observer robots expose the same ROS interface, and can be interacted with
in the same way. As Husky Observer is built on top of the Husky base robot, you can follow the
[Husky Tutorials](/docs/robots/outdoor_robots/husky/tutorials_husky/tutorials_husky_ros1#interfacing-with-husky)
for interfacing with Husky Observer.

### Driving Husky Observer {#driving-husky-observer}

There are four ways to drive Husky Observer and each way will work on a physical Husky Observer robot as well as on a simulated Husky Observer.

1. Using the interactive remote controller in RViz. See [Simulating Husky Observer](#simulating-husky-observer).
2. Using autonomous navigation. See the [OutdoorNav User Manual](/docs_outdoornav_user_manual).
3. Using the controller for teleoperation. See [Husky Tutorials](/docs/robots/outdoor_robots/husky/tutorials_husky/tutorials_husky_ros1#driving-with-remote-controller).
4. Publishing ROS messages. See [Husky Tutorials](/docs/robots/outdoor_robots/husky/tutorials_husky/tutorials_husky_ros1#driving-with-ros-messages).

### Keeping Husky Observer Updated

For details on updating Husky Observer software or firmware, refer to [Software Maintenance](/docs/robots/solutions/husky_observer/maintenance_husky#software_maintenance).

---

## Testing Base Husky

See [Husky Tutorials](/docs/robots/outdoor_robots/husky/tutorials_husky/tutorials_husky_ros1#testing-husky) for
details on how to validate that the base Husky platform is operating as expected.

TODO: do we want to add any tests for the sensors that are specific to Husky Observer?

---

## Support {#support}

<Support />

