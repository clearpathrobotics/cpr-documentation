---
title: Dingo Tutorials
sidebar_label: Tutorials
sidebar_position: 4
---

import ComponentIntroductionDingo from "/components/introduction_dingo.mdx";
import ComponentPs4ControllerPairing from "/components/ps4_controller_pairing.mdx";
import ComponentChangingDefaultPassword from "/components/changing_default_password.mdx";
import ComponentWiredRobotConnection from "/components/wired_robot_connection.mdx";
import ComponentWifiRobotConnection from "/components/wifi_robot_connection.mdx";
import ComponentConfiguringNetworkBridge from "/components/configuring_network_bridge.mdx";
import ComponentPerformingABackup from "/components/performing_a_backup.mdx";
import ComponentInstallingRobotSoftware from "/components/installing_robot_software.mdx";
import ComponentInstallingRemoteComputerSoftware from "/components/installing_remote_computer_software.mdx";
import ComponentAddingASourceWorkspace from "/components/adding_a_source_workspace.mdx";
import ComponentDrivingWithRemoteController from "/components/driving_with_remote_controller.mdx";
import Support from "/components/support.mdx";

<ComponentIntroductionDingo />

## Dingo Overview

### Introduction

Dingo a lightweight and easy-to-use unmanned indoor ground vehicle for ROS, suitable for research and rapid prototyping applications.
These tutorials will assist you with setting up and operating your Dingo.
The tutorial topics are listed in the right column and presented in the suggested reading order.

For more information or to receive a quote, please [visit us online](http://clearpathrobotics.com/dingo).

:::note

These tutorials assume that you are comfortable working with ROS.
We recommend starting with our [ROS tutorial](https://www.clearpathrobotics.com/assets/guides/noetic/ros/index.html) if you are not familiar with ROS already.

:::

:::note

These tutorials specifically target Dingo robots running Ubuntu 20.04 with ROS Noetic, as it is the standard OS environment for Dingo.
If instead you have an older Dingo robot running Ubuntu 18.04 with ROS Melodic, please follow [this tutorial](https://www.clearpathrobotics.com/assets/guides/melodic/melodic-to-noetic/index.html) to upgrade the robot OS environment to Ubuntu 20.04 with ROS Noetic.

:::

[Dingo ROS Packages](#dingo-ros-packages) provides the references for the software packages and key ROS topics.

[Dingo Software Setup](#dingo-software-setup) outlines the steps for setting up the software on your Dingo robot and optionally on a remote computer.

[Using Dingo](#using-dingo) describes how to simulate and drive your Dingo. [Simulation](#simulating-dingo) is a great way for most users to learn more about their Dingo;
understanding how to effectively operate Dingo in simulation is valuable whether you are in the testing phase with software you intend to ultimately deploy on a physical Dingo or you do not have one and are simply exploring the platform's capabilities.
[Driving Dingo](#driving-dingo) covers how to teleoperate Dingo using the remote control, as well as safety procedures for operating the physical robot.
Anyone working with a physical robot should be familiar with this section.

[Navigating Dingo](#navigating-dingo) is a follow-on to what is learned in the [Simulation](#simulating-dingo) tutorial, as navigation and map-making may be run in the simulated environment.
However, this content is applicable to both the simulator and the real platform, if your Dingo is equipped with a laser scanner.

[Dingo Tests](#testing-dingo) outlines how to validate that your physical Dingo is working correctly.

[Advanced Topics](#advanced-topics) covers items that are only required in atypical situations.

---

## Dingo ROS Packages {#dingo-ros-packages}

Dingo fully supports ROS; all of the packages are available in [Dingo Github](https://github.com/dingo-cpr).

### Description Package {#description-package}

The [dingo_description](https://github.com/dingo-cpr/dingo/tree/melodic-devel/dingo_description) repository provides a [URDF](http://wiki.ros.org/urdf) model of Dingo.

Dingo's URDF model can be visualized in RViz.
Once you have installed the desktop software in an upcoming tutorial, you will be able to run:

```
roslaunch dingo_viz view_model.launch
```

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo_urdf.png"
      width="600"
    />
    <figcaption>Dingo model</figcaption>
  </figure>
</center>

### Environment Variables

Dingo can be customized and extended through the use of several environment variables.
These are summarized in the [README](https://github.com/dingo-cpr/dingo/blob/melodic-devel/dingo_description/README.md) file.
Some of the most important ones are listed below.

| Variable                | Default | Description                                                                 |
| :---------------------- | :------ | :-------------------------------------------------------------------------- |
| `DINGO_OMNI`            | `0`     | Set to 1 to switch from Dingo-D to Dingo-O (with omnidirectional wheels)    |
| `DINGO_LASER`           | `0`     | Set to 1 to equip Dingo with a primary lidar unit, normally front-facing    |
| `DINGO_LASER_SECONDARY` | `0`     | Set to 1 to equip Dingo with a secondary lidar unit, normally rear-facing   |
| `DINGO_LASER_3D`        | `0`     | Set to 1 to equip Dingo with a primary 3D lidar unit, normally front-facing |
| `DINGO_REALSENSE`       | `0`     | Set to 1 to equip Dingo with a RealSense depth camera                       |
| `DINGO_IMU_MICROSTRAIN` | `0`     | Set to 1 to equip Dingo with a Microstrain IMU                              |

### Mounting points

Dingo-D has 6 evenly-spaced mounting points along its center channel for mounting sensors and other accessories.
Dingo-O has 7 similar mounting points.
The centers of these mounting points are represented as links in the URDF to facilitate adding sensors to simulated robots and modelling collisions when planning arm motions for mobile manipulation.

| Link (front to back) | Dingo-D | Dingo-O |
| :------------------- | :------ | :------ |
| `front_mount`        | Yes     | Yes     |
| `front_b_mount`      | Yes     | Yes     |
| `front_c_mount`      | Yes     | Yes     |
| `mid_mount`          | No      | Yes     |
| `rear_c_mount`       | Yes     | Yes     |
| `rear_b_mount`       | Yes     | Yes     |
| `rear_mount`         | Yes     | Yes     |

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo-d-mounts.png"
      width="600"
    />
    <figcaption>Dingo-D mount points</figcaption>
  </figure>
</center>

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo-o-mounts.png"
      width="600"
    />
    <figcaption>Dingo-O mount points</figcaption>
  </figure>
</center>

Both versions of Dingo also provide a `front_bumper_mount`, located directly on the front of the robot.
While the physical robot does not have any mounting holes here, lightweight sensors (e.g. small cameras) can be placed here using double-sided adhesive if required.

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo-d-front_bumper_mount.png"
      width="600"
    />
    <figcaption>Dingo-D front bumper mount</figcaption>
  </figure>
</center>

### Configurations

As an alternative to individually specifying each accessory, some fixed configurations are provided in the package.
These can be specified using the `config` arg to `description.launch`, and are intended especially as a convenience for simulation launch.

| Config        | Description                                         |
| :------------ | :-------------------------------------------------- |
| `base`        | Base Dingo                                          |
| `front_laser` | Adds a SICK LMS1xx lidar to the Dingo's front mount |

:::note

Additional configurations coming soon

:::

### Key ROS Topics

You can view all topics that are active using `rostopic list`.
The most important topics are summarized in the table below.

| Topic                | Message Type          | Purpose                                                                                                                                                                                                        |
| :------------------- | :-------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `/cmd_vel`           | `geometry_msgs/Twist` | Input to Dingo's kinematic controller. Publish here to make Dingo go.                                                                                                                                          |
| `/odometry/filtered` | `nav_msgs/Odometry`   | Published by `robot_localization`, a filtered localization estimate based on wheel odometry (encoders) and integrated IMU.                                                                                     |
| `/imu/data`          | `sensor_msgs/IMU`     | Published by `imu_filter_madgwick`, an orientation estimated based on the Dingo's internal IMU.                                                                                                                |
| `/mcu/status`        | `dingo_msgs/Status`   | Low-frequency status data for Dingo's systems. This information is republished in human readable form on the `diagnostics` topic and is best consumed with the Robot Monitor.                                  |
| `/mcu/aux_input`     | `dingo_msgs/UInt8`    | User can subscribe to this topic to monitor the MCU user inputs. See [AUX Inputs](/docs/robots/indoor_robots/dingo/integration_dingo#dingo-aux-inputs).                                                        |
| `/mcu/aux_output`    | `std_msgs/UInt8`      | User can publish to this topic to enable and disable the AUX outputs as well as control relays on the MCU. See [AUX Outputs and Relays](/docs/robots/indoor_robots/dingo/integration_dingo#dingo-aux-outputs). |
| `/mcu/fans`          | `dingo_msgs/Fans`     | User can publish to this topic to control an optionally installed fan. See details [Optional Fan](/docs/robots/indoor_robots/dingo/integration_dingo#dingo-fan).                                               |
| `/mcu/lights`        | `dingo_msgs/Lights`   | User can publish to this topic to override the default behavior of the Dingo corner LEDs.                                                                                                                      |

---

## Dingo Software Setup {#dingo-software-setup}

### Backing Up Robot Configuration

Upgrading your Clearpath Dingo to ROS Noetic from older ROS distributions is a straightforward process;
however it's important to understand that each Dingo is different, having undergone customization to your specifications.
For more complete upgrade instructions see [this guide](https://clearpathrobotics.com/assets/guides/melodic/melodic-to-noetic/index.html).

Please take the time to understand what these modifications are, and how to recreate them on your fresh install of Ubuntu Focal/ROS Noetic.

#### Performing a Backup {#performing-a-backup}

<ComponentPerformingABackup />

### Installing and Configuring Robot Software

:::note

If you are upgrading your Dingo from an older version of ROS, please refer to our upgrade instructions [here](https://clearpathrobotics.com/assets/guides/kinetic/kinetic-to-melodic/index.html)
and [here](https://clearpathrobotics.com/assets/guides/melodic/melodic-to-noetic/index.html).

:::

#### Installing Dingo Software

:::note

The physical Dingo robot comes pre-configured with ROS and the necessary Dingo packages already installed;
therefore, you will only need to follow the instructions below if you are re-installing software on the Dingo.

:::

<ComponentInstallingRobotSoftware />

#### Testing Base Configuration

1. To test your configuration, start the background service with the following command:

   ```
   sudo systemctl start ros
   ```

2. The Comms indicator <img src="/img/robot_images/dingo_images/icon-comms.png" width="20" />
   should turn green. You can check that the service has started correctly by checking the logs:

   ```
   sudo journalctl -u ros
   ```

3. Your Dingo should now be accepting commands from your joystick (see next section).
   The service will automatically start each time you boot your Dingo's computer.

#### Pairing the Controller {#pairing-the-controller}

##### PS4 Controller

<ComponentPs4ControllerPairing />

### Setting up Dingo's Network Configuration {#dingo-networking}

Dingo is normally equipped with a combination Wi-Fi + Bluetooth module.
If this is your first unboxing, ensure that Dingo's wireless antennae are firmly screwed on to the chassis.

#### First Connection

By default, Dingo's Wi-Fi is in client mode, looking for the wireless network at the Clearpath factory.

<ComponentWiredRobotConnection />

#### Changing the Default Password

<ComponentChangingDefaultPassword />

#### Wi-Fi Setup

<ComponentWifiRobotConnection />

### Installing Remote Computer Software {#remote-computer-software}

:::note

This step is optional.

:::

<ComponentInstallingRemoteComputerSoftware />

#### Adding a Source Workspace

<ComponentAddingASourceWorkspace />

---

## Using Dingo {#using-dingo}

### Simulating Dingo {#simulating-dingo}

Whether you actually have a Dingo robot or not, the Dingo simulator is a great way to get started with ROS robot development.
In this tutorial, we will go through the basics of starting Gazebo and RViz and how to drive your Dingo around.

#### Installation

To get started with the Dingo simulation, make sure you have a [working ROS installation](#remote-computer-software) set up on your Ubuntu desktop, and install the Dingo-specific metapackages for desktop and simulation:

```
sudo apt-get install ros-noetic-dingo-simulator ros-noetic-dingo-desktop
```

#### Launching Gazebo

[Gazebo](https://gazebosim.org/home) is the most common simulation tool used in ROS. Dingo's model in Gazebo include reasonable approximations of its dynamics, including wheel slippage, skidding, and inertia.
To launch simulated Dingo in a simple example world, run the following command:

```
roslaunch dingo_gazebo dingo_world.launch
```

You should see the following window appear, or something like it.
You will see a base Dingo spawned with no additional sensors.
You can adjust the camera angle by clicking and dragging while holding CTRL, ALT, or the Shift key.

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo_gazebo.png"
      width="800"
    />
    <figcaption>Simulated Dingo in the Race World</figcaption>
  </figure>
</center>

The window which you are looking at is the Gazebo Client.
This window shows you the "true" state of the simulated world which the robot exists in.
It communicates on the backend with the Gazebo Server, which is doing the heavy lifting of actually maintaining the simulated world.
At the moment, you are running both the client and server locally on your own machine, but some advanced users may choose to run heavy duty simulations on separate hardware and connect to them over the network.

:::note

When simulating, you must leave Gazebo running.
Closing Gazebo will prevent other tools, such as RViz (see below) from working correctly.

:::

:::note

See also [Additional Simulation Worlds](#additional-sim).

:::

##### Simulation Configs

Note that like Dingo itself, Dingo's simulator comes in multiple flavours called configs.
A common one which you will need often is the `front_laser` config.
If you close the Gazebo window, and then CTRL-C out of the terminal process, you can re-launch the simulator with a specific config.

```
roslaunch dingo_gazebo dingo_world.launch config:=front_laser
```

You should now see the simulator running with the simulated SICK LMS-111 laser present.

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo_gazebo_laser.png"
      width="800"
    />
    <figcaption>Simulated Dingo in the Race World with SICK LMS-111</figcaption>
  </figure>
</center>

Gazebo not only simulates the physical presence of the laser scanner, it also provides simulated data which reflects the robot's surroundings in its simulated world.
We will visualize the simulated laser scanner data shortly.

### Interfacing with Dingo

Both simulated and real Dingo robots expose the same ROS interface and can be interacted with in the same way.

:::note

Please make sure that the desktop packages for Dingo are installed:

```
sudo apt-get install ros-noetic-dingo-desktop
```

:::

#### Launching RViz

The next tool we will encounter is [RViz](http://wiki.ros.org/rviz).
Although superficially similar in appearance to Gazebo, RViz has a very different purpose. Unlike Gazebo, which shows the reality of the simulated world, RViz shows the robot's _perception_ of its world, whether real or simulated.
So while Gazebo won't be used with your real Dingo, RViz is used with both.

You can use the following launch invocation to start RViz with a predefined configuration suitable for visualizing any standard Dingo config.

```
roslaunch dingo_viz view_robot.launch
```

You should see RViz appear.

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo_rviz.png"
      width="800"
    />
    <figcaption>Dingo RViz</figcaption>
  </figure>
</center>

The RViz display only shows what the robot knows about its world, which presently, is nothing.
Because the robot doesn't yet know about the barriers which exist in its Gazebo world, they are not shown here.

#### Driving with Interactive Controller

RViz will also show Dingo's interactive markers around your Dingo's model.
These will appear as a blue ring and red arrows.
Depending on your robot, there will also be green arrows.
If you don't see them in your RViz display, select the Interact tool from the top toolbar and they should appear.

Drag the red arrows in RViz to move in the linear X direction, and the blue circle to move in the angular Z direction.
If your robot supports lateral/sideways movement, you can drag the green arrows to move in the linear Y direction.
RViz shows you Dingo moving relative to its odometric frame, but it is also moving relative to the simulated world supplied by Gazebo.
If you click over to the Gazebo window, you will see Dingo moving within its simulated world.
Or, if you drive real Dingo using this method, it will have moved in the real world.

#### Visualizing Sensors

The RViz tool is capable of visualizing many common robotic sensors, as well as other data feeds which can give us clues as to what the robot is doing and why.
A great place to start with this is adding the [LaserScan](http://wiki.ros.org/rviz/DisplayTypes/LaserScan) plugin to visualize the laser scans being produced by the simulated LMS-111. In the left panel, click the "Add" button, then select the "Topics" tab, and then select the `front/scan` topic:

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo_rviz_add_laser.png"
      width="800"
    />
    <figcaption>Adding a laser scan visualization to Dingo</figcaption>
  </figure>
</center>

Click "OK" and you should see laser scan points now visible in the RViz window, relative to the robot.

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo_rviz_laser.png"
      width="800"
    />
    <figcaption>Visualizing Dingo with simulated laser scans</figcaption>
  </figure>
</center>

If you use the interactive markers to drive around, you'll notice that the laser scan points move a little bit but generally stay where they are.
This is the first step toward map making using [Gmapping](#gmapping-demo).

#### Control

There are three ways to send your Dingo control commands:

1.  Using the provided PS4 controller.
    Refer to the [User Manual](/docs/robots/indoor_robots/dingo/user_manual_dingo/#controller) details on how to use the controller.

2.  Using the RViz instance above.
    If you select the Interact option in the top toolbar, an interactive marker will appear around the Dingo and can be used to control speed.

3.  The [rqt_robot_steering plugin](http://wiki.ros.org/rqt_robot_steering).
    Run the `rqt` command, and select **Plugins→Robot Tools→Robot Steering** from the top menu.

Dingo uses [twist_mux](http://wiki.ros.org/twist_mux) to mix separate [geometry_msgs\Twist](http://docs.ros.org/api/geometry_msgs/html/msg/Twist.html) control channels into the `dingo_velocity_controller/cmd_vel` topic.

Additional velocity channels can be defined in [twist_mux.yaml](https://github.com/dingo-cpr/dingo/blob/melodic-devel/dingo_control/config/twist_mux.yaml), or can be piped into the lowest-priority `cmd_vel` topic.

#### Odometry

Dingo publishes odometry information on the `odometry/filtered` topic, as [nav_msgs/Odometry messages](http://docs.ros.org/api/nav_msgs/html/msg/Odometry.html).
These are generated by [ekf_localization_node](http://wiki.ros.org/robot_localization), which processes data from several sensor sources using an Extended Kalman filter (EKF).
This includes data from the wheel encoders and IMU (if available).

Additional odometry information sources can be added to the EKF in [robot_localization.yaml](https://github.com/dingo-cpr/dingo/blob/melodic-devel/dingo_control/config/robot_localization.yaml).

#### Diagnostics

:::note

Diagnostics are only applicable to real Dingo robots, not simulation.

:::

Dingo provides hardware and software system [diagnostics](http://wiki.ros.org/diagnostics) on the ROS standard `/diagnostics` topic.
The best way to view these messages is using the [rqt_runtime_monitor](http://wiki.ros.org/rqt_runtime_monitor) plugin.
Run the `rqt` command, and select **Plugins→Robot Tools→Runtime Monitor** from the top menu.

The same information is also published as a [dingo_msgs\Status](https://docs.ros.org/en/api/dingo_msgs/html/msg/Status.html) message on the `Status` topic.

### Driving Dingo {#driving-dingo}

There are four ways to drive Dingo and each way will work on a physical Dingo robot as well as on a simulated Dingo.

1.  Using the interactive remote controller in RViz. See [Simulating Dingo](#simulating-dingo).
2.  Using autonomous navigation. See [Navigating Dingo](#navigating-dingo).
3.  Using the controller for teleoperation. See below.
4.  Publishing ROS messages. See below.

:::warning

Dingo is capable of reaching high speeds.
Careless driving can cause harm to the operator, bystanders, the robot, or other property.
Always remain vigilant, ensure you have a clear line of sight to the robot, and operate the robot at safe speeds.
We strongly recommend driving in normal (slow) mode first, and only enabling turbo in large, open areas that are free of people and obstacles.

:::

#### Driving with Remote Controller

:::note

For instructions on controller pairing, [Pairing the Controller](#pairing-the-controller).

:::

<ComponentDrivingWithRemoteController />

#### Driving with ROS Messages

You can manually publish `geometry_msgs/Twist` ROS messages to either the `/dingo_velocity_controller/cmd_vel` or the `/cmd_vel` ROS topics to drive Dingo.

For example, in terminal, run:

```
rostopic pub /dingo_velocity_controller/cmd_vel geometry_msgs/Twist '{linear: {x: 0.5, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: 0.0}}'
```

The command above makes Dingo drive forward momentarily at 0.5 m/s without any rotation.

### Extending Dingo Startup

Now that you've had Dingo for a while, you may be interested in how to extend it, perhaps add some more payloads, or augment the URDF.

#### Startup Launch Context

When ROS packages are grouped together in a directory and then built as one, the result is referred to as a workspace.
Each workspace generates a `setup.bash` file which the user may source in order to correctly set up important environment variables such as `PATH`, `PYTHONPATH`, and `CMAKE_PREFIX_PATH`.

The standard system-wide setup file is in `opt`:

```
source /opt/ros/noetic/setup.bash
```

When you run this command, you'll have access to `rosrun`, `roslaunch`, and all the other tools and packages installed on your system from Debian packages.

However, sometimes you want to add additional system-specific environment variables, or perhaps packages built from source.
For this reason, Clearpath platforms use a wrapper setup file, located in `/etc/ros`:

```
source /etc/ros/setup.bash
```

This is the setup file which gets sourced by Dingo's background launch job, and in the default configuration, it is also sourced on your login session.
For this reason it can be considered the "global" setup file for Dingo's ROS installation.

This file sets some environment variables and then sources a chosen ROS workspace, so it is one of your primary modification points for altering how Dingo launches.

#### Launch Files

The second major modification point is the `/etc/ros/noetic/ros.d` directory.
This location contains the launch files associated with the `ros` background job.
If you add launch files here, they will be launched with Dingo's startup.

However, it's important to note that in the default configuration, any launch files you add may only reference ROS software installed in `/opt/ros/noetic`.
If you want to launch something from workspace in the home directory, you must change `/etc/ros/setup.bash` to source that workspace's setup file rather than the one from `opt`.

#### Adding URDF

There are two possible approaches to augmenting Dingo's URDF.
The first is that you may simply set the `Dingo_URDF_EXTRAS` environment variable in `/etc/ros/setup.bash`.
By default, it points to an empty dummy file, but you can point it to a file of additional links and joints which you would like mixed into Dingo's URDF (via xacro) at runtime.

The second, more sophisticated way to modify the URDF is to create a _new_ package for your own robot, and build your own URDF which wraps the one provided by [dingo_description](https://github.com/dingo-cpr/dingo/tree/melodic-devel/dingo_description).

### Keeping Dingo Updated

For details on updating Dingo software or firmware, refer to [Software Maintenance](/docs/robots/indoor_robots/dingo/maintenance_dingo#software_maintenance).

---

## Navigating Dingo {#navigating-dingo}

To get all Navigation related files for Dingo, run:

```
sudo apt-get install ros-noetic-dingo-navigation
```

Below are the example launch files for three different configurations for navigating Dingo:

- Navigation in an odometric frame without a map, using only [move_base](http://wiki.ros.org/move_base).
- Generating a map using [gmapping](http://wiki.ros.org/gmapping).
- Localization with a known map using [amcl](http://wiki.ros.org/amcl).

Referring to the [Simulating Dingo](#simulating-dingo) instructions, bring up Dingo with the front laser enabled for the following demos:

```
roslaunch dingo_gazebo dingo_world.launch config:=front_laser
```

If you're working with a real Dingo, it's suggested to connect via SSH and launch the [dingo_navigation](https://github.com/dingo-cpr/dingo/tree/melodic-devel/dingo_navigation) launch files from on board the robot.
You'll need to have bidirectional communication with the robot's roscore in order to launch RViz on your workstation (see [here](#remote-computer-software)).

### Navigation without a Map

In the odometry navigation demo Dingo attempts to reach a given goal in the world within a user-specified tolerance.
The 2D navigation, generated by `move_base`, takes in information from odometry, laser scanner, and a goal pose and outputs safe velocity commands.
In this demo the configuration of move_base is set for navigation without a map in an odometric frame (that is, without reference to a map).

To launch the navigation demo, run:

```
roslaunch dingo_navigation odom_navigation_demo.launch
```

To visualize with the suggested RViz configuration launch:

```
roslaunch dingo_viz view_robot.launch config:=navigation
```

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/rviz-odom-navigation.png"
      width="800"
    />
    <figcaption>RViz with Dingo's odom navigation configuration</figcaption>
  </figure>
</center>

To send goals to the robot, select the _2D Nav Goal_ tool from the top toolbar, and then click anywhere in the RViz view to set the position.
Alternatively, click and drag slightly to set the goal position and orientation.

If you wish to customize the parameters of move_base, local costmap, global costmap and base_local_planner, clone [dingo_navigation](https://github.com/dingo-cpr/dingo/tree/melodic-devel/dingo_navigation) into your own workspace and modify the corresponding files in the `params` subfolder.

### Making a Map {#gmapping-demo}

In this demonstration, Dingo generates a map using Gmapping. Begin by launch the Gmapping launch file on the robot:

```
roslaunch dingo_navigation gmapping_demo.launch
```

And on your workstation, launch RViz with the suggested configuration:

```
roslaunch dingo_viz view_robot.launch config:=gmapping
```

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/rviz-gmapping.png"
      width="800"
    />
    <figcaption>RViz with Dingo's Gmapping configuration</figcaption>
  </figure>
</center>

You must slowly drive Dingo around to build the map.
As obstacles come into view of the laser scanner, they will be added to the map, which is shown in RViz.
You can either drive manually using the interactive markers, or semi-autonomously by sending navigation goals (as above).

When you're satisfied, you can save the produced map using [map_saver](http://wiki.ros.org/map_server#map_saver):

```
rosrun map_server map_saver -f mymap
```

This will create a `mymap.yaml` and `mymap.pgm` file in your current directory.

### Navigation with a Map

Using [amcl](http://wiki.ros.org/amcl), Dingo is able to globally localize itself in a known map.
AMCL takes in information from odometry, laser scanner and an existing map and estimates the robot's pose.

To start the AMCL demo:

```
roslaunch dingo_navigation amcl_demo.launch map_file:=/path/to/my/map.yaml
```

If you don't specify `map_file`, it defaults to an included pre-made map of the default "Dingo Race" environment which Dingo's simulator spawns in.
If you're using a real Dingo in your own environment, you'll definitely want to override this with the map created using the Gmapping demo.

Before navigating, you need to initialize the localization system by setting the pose of the robot in the map.
This can be done using 2D Pose Estimate in RViz or by setting the amcl `initial_pose` parameters. To visualize with the suggested RViz configuration launch:

```
roslaunch dingo_viz view_robot.launch config:=localization
```

When RViz appears, select the _Set 2D Pose tool_ from the toolbar, and click on the map to indicate to the robot approximately where it is.

---

## Dingo Tests {#testing-dingo}

Dingo robots come preinstalled with a set of test scripts as part of the `dingo_tests` ROS package, which can be run to verify robot functionality at the component and system levels.

If your Dingo does not have the `dingo_tests` ROS package installed already, you can manually install it by opening terminal and running:

```
sudo apt-get install ros-noetic-dingo-tests
```

### ROS Tests

The `ros_tests` script exposes a set of interactive tests to verify the functionality of core features.
These tests run at the ROS-level via ROS topics, and serve as a useful robot-level diagnostic tool for identifying the root cause of problems, or at the very least, narrowing down on where the root cause(s) may be.

#### Running ROS Tests

To run `ros_tests` on a Dingo robot, open terminal and run:

```
rosrun dingo_tests ros_tests
```

Upon running `ros_tests`, a list of available tests will be shown in a menu.
From the menu, you can choose individual tests to run, or simply choose the option to automatically run all the tests.

The details of each test are shown below.

- **Lighting Test**

  The **Lighting Test** checks that the robot's lights are working properly.

  This test turns the lights off, red, green, and blue (in order) by publishing lighting commands to the `/cmd_lights` ROS topic.
  The user will be asked to verify that the lights change to the expected colours.

- **Motion Stop Test**

  The **Motion Stop Test** checks that the robot's motion-stop is working properly.

  This test subscribes to the `/mcu/status` ROS topic and checks that when the motion-stop is manually engaged by the user, the motion-stop state is correctly reported on the `/mcu/status` ROS topic.
  The user will be asked to verify that the lights flash red while the motion-stop is engaged.

- **ADC Test**

  The **ADC Test** checks that the robot's voltage and current values across its internal hardware components are within expected tolerances.

  This test subscribes to the `/mcu/status` ROS topic and checks that the voltage and current values across the internal hardware are within expected tolerances.

- **Rotate Test**

  The **Rotate Test** rotates the robot counter clockwise 2 full revolutions and checks that the motors, IMU, and EKF odometry are working properly.

  This test:

  - Subscribes to the `/imu/data` ROS topic to receive angular velocity measurements from the IMU's Gyroscope.
    These measurements are converted into angular displacement estimations, and the robot will rotate until 2 full revolutions are estimated.
  - Subscribes to the `/odometry/filtered` ROS topic to receive angular velocity estimations from the EKF odometry.
    These measurements are converted into angular displacement estimations, and are output as comparison to the angular displacement estimations from the IMU's Gyroscope.
  - Publishes to the `/cmd_vel` ROS topic to send drive commands to rotate the robot.
  - The user will be asked to verify that the robot rotates 2 full revolutions.

  :::note

  The **Rotate Test** rotates the robot using the IMU's Gyroscope data, which inherently will not be 100% accurate.
  Therefore, some undershoot/overshoot is to be expected.

  :::

- **Drive Test**

  The **Drive Test** drives the robot forward 1 metre and checks that the motors, encoders, and encoder-fused odometry are working properly.

  This test:

  - Subscribes to the `/dingo_velocity_controller/odom` ROS topic to receive linear displacement estimations from the encoder-fused odometry.
    The robot will drive forward until 1 metre is estimated.
  - Subscribes to the `/feedback` ROS topic to receive linear displacement measurements from the individual encoders.
    These measurements are output as comparison to the linear displacement estimations from the encoder-fused odometry.
  - Subscribes to the `/joint_state` ROS topic to receive linear displacement measurements from individual the encoders.
    These measurements are output as comparison to the linear displacement estimations from the encoder-fused odometry.
  - Publishes to the `/cmd_vel` ROS topic to send drive commands to drive the robot.
  - The user will be asked to verify that the robot drives forward 1 metre.

  :::note

  The **Drive Test** drives the robot using the Odometry data, which inherently will not be 100% accurate.
  Therefore, some undershoot/overshoot is to be expected.

  :::

- **Cooling Test**

  The **Cooling Test** is an optional test that only applies to Dingo's with an external fan connected to the MCU, and checks that the external fan is working properly.

  This test makes the fan spin at different speeds by publishing fan speed commands to the `/mcu/cmd_fans` ROS topic.
  The user will be asked to verify that the fan change to the expected speeds.

### CAN Bus Test

The `check_can_bus_interface` script checks that communication between the motors, encoders, robot's MCU, and robot's computer are working properly over the CAN bus interface.

This script verifies that the `can0` interface is detected and activated, then proceeds to check the output of `candump` to verify that good CAN packets are being transmitted.
Based on the Dingo configuration, either Dingo-D or Dingo-O, this script will know to check for good CAN packets from 2 or 4 encoders, respectively.

#### Running CAN Bus Test

To run the `check_can_bus_interface` script on a Dingo robot, open terminal and run:

```
rosrun dingo_tests check_can_bus_interface
```

---

## Advanced Topics

### Configuring the Network Bridge

<ComponentConfiguringNetworkBridge />

### Jetson Installation

Refer to the [Jetson](/docs/computers/jetson/jetson_hardware) page for details on installing a Jetson in Dingo.

### Additional Simulation Worlds {#additional-sim}

In addtion to the default `dingo_world.launch` file, `dingo_gazebo` contains two additional launch files:

- `empty_world.launch`, which spawns Dingo in a featureless, infinite plane;
- `spawn_dingo.launch`, which is intended to be included in any custom world to add a Dingo simulation to it.

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo_empty_world.png"
      width="800"
    />
    <figcaption>Dingo in the Empty World environment</figcaption>
  </figure>
</center>

To add a Dingo to any of your own worlds, simply include the `spawn_dingo.launch` file in your own world's launch:

```markup
<include file="$(find dingo_gazebo)/launch/spawn_dingo.launch">
  <!-- Optionally configure the spawn position -->
  <arg name="x" value="$(arg x)"/>
  <arg name="y" value="$(arg y)"/>
  <arg name="z" value="$(arg z)"/>
  <arg name="yaw" value="$(arg yaw)"/>
</include>
```

Finally, Clearpath provides an additional suite of simulation environments that can be downloaded separately and used with Dingo, as described below.

#### Clearpath Gazebo Worlds

The Clearpath Gazebo Worlds collection contains 4 different simulation worlds, representative of different environments our robots are designed to operate in:

- Inspection World: a hilly outdoor world with water and a cave
- Agriculture World: a flat outdoor world with a barn, fences, and solar farm
- Office World: a flat indoor world with enclosed rooms and furniture
- Construction World: office world, under construction with small piles of debris and partial walls

Dingo is supported in the Office and Construction worlds.

#### Installation

To download the Clearpath Gazebo Worlds, clone the repository from github into the same workspace as your Dingo:

```
cd ~/catkin_ws/src
git clone https://github.com/clearpathrobotics/cpr_gazebo.git
```

Before you can build the package, make sure to install dependencies.
Because Clearpath Gazebo Worlds depends on all of our robot's simulation packages, and some of these are currently only available as source code, installing dependencies with `rosdep install --from-paths [...]` will likely fail.

To simulate Dingo in the Office and Construction worlds the only additional dependency is the `gazebo_ros` package.

Once the dependencies are installed, you can build the package:

```
cd ~/catkin_ws
catkin_make
source devel/setup.bash
```

#### Running the Office Simulation

Office World is a small indoor environment representing a commercial office space. It features several large, open
areas with furniture, as well as a narrow hallway with smaller offices and meeting rooms. It is intended to simulate
missions in commercial spaces, such as facilitating deliveries, security monitoring, and inspecting equipment.

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo_office_world.png"
      width="800"
    />
    <figcaption>Dingo in the Office World</figcaption>
  </figure>
</center>

To launch Office World with a Dingo, run the following command:

```
roslaunch cpr_office_gazebo office_world.launch platform:=dingo
```

You should see Dingo spawn in the office world, as pictured. You can see the complete layout of the office below:

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/office_world.png"
      width="800"
    />
    <figcaption>The layout of Office World</figcaption>
  </figure>
</center>

To add sensors to Dingo, use the environment variables described in [Description Package](#description-package).
For example, to simulate Dingo with a Sick LMS-1xx lidar, run:

```
export DINGO_LASER=1
roslaunch cpr_office_gazebo office_world.launch platform:=dingo
```

You will see Dingo spawn with a lidar sensor mounted to it, which can be used for navigation as described in
[Simulating Dingo](#simulating-dingo).

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo_office_laser.png"
      width="800"
    />
    <figcaption>Dingo in Office World with a lidar sensor</figcaption>
  </figure>
</center>

#### Running the Construction Simulation

Construction World is the same basic layout as Office World, representing the same office space under construction/renovation.
It is an indoor environment with small hills of debris/rubble, partial walls, and piles of construction supplies. It
is designed to simulate missions in any sort of construction site.

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/dingo_construction_world.png"
      width="800"
    />
    <figcaption>Dingo in the Construction World</figcaption>
  </figure>
</center>

To launch Construction World with a Dingo, run the following command:

```
roslaunch cpr_office_gazebo office_construction_world.launch platform:=dingo
```

You should see Dingo spawn in the construction world, as pictured. You can see the complete layout of the office below:

<center>
  <figure>
    <img
      src="/img/robot_images/dingo_images/construction_world.png"
      width="800"
    />
    <figcaption>The layout of Construction World</figcaption>
  </figure>
</center>

To add sensors to Dingo, use the environment variables described in [Description Package](#description-package).
For example, to simulate Dingo with a Sick LMS-1xx lidar, run:

```
export DINGO_LASER=1
roslaunch cpr_office_gazebo office_construction_world.launch platform:=dingo
```

You will see Dingo spawn with a lidar sensor mounted to it, which can be used for navigation as described in [Simulating Dingo](#simulating-dingo).

---

## Support {#support}

<Support />
